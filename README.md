ğŸ“¦ FleetLogix Data Engineering Project

ModernizaciÃ³n completa del ecosistema de datos para una empresa de logÃ­stica con flota de 200 vehÃ­culos

ğŸ“˜ IntroducciÃ³n

FleetLogix es una empresa de transporte y logÃ­stica que opera entregas de Ãºltima milla en 5 ciudades. Ante la necesidad de modernizar sus sistemas legacy y planillas, el proyecto consiste en construir una soluciÃ³n de datos integral que abarque:

Modelado relacional en PostgreSQL

GeneraciÃ³n masiva de datos sintÃ©ticos realistas

ValidaciÃ³n de integridad referencial

Consultas avanzadas para resolver problemas operativos

MigraciÃ³n y procesamiento en Snowflake

Arquitectura cloud serverless en AWS

Pipelines automÃ¡ticos de ingesta y anÃ¡lisis

Este proyecto fue desarrollado en el marco del MÃ³dulo 2 â€“ Data Science.

ğŸ¯ Objetivos del Proyecto

Dominar SQL (CTEs, Window Functions, optimizaciÃ³n de queries)

Generar datos sintÃ©ticos masivos con integridad y realismo

Transformar un modelo OLTP en un Data Warehouse dimensional

Implementar arquitectura cloud con AWS (RDS, S3, Lambda, API Gateway, DynamoDB)

Integrar bases NoSQL para datos no estructurados (MongoDB/DynamoDB)

Desarrollar pipelines ETL en Python

Aplicar buenas prÃ¡cticas de arquitectura de datos

ğŸ—„ï¸ Modelo Relacional en PostgreSQL

El modelo proporcionado incluye 6 tablas principales:

â–« Tablas DimensiÃ³n

vehicles

drivers

routes

â–« Tablas de Hechos

trips

deliveries

maintenance

Se documentaron claves primarias, forÃ¡neas, constraints e Ã­ndices.
Posteriormente se creÃ³ el esquema completo en PostgreSQL con scripts de creaciÃ³n, Ã­ndices y comentarios, y una tabla adicional logs_ingesta para registrar cada carga de datos.

ğŸ§ª GeneraciÃ³n de Datos SintÃ©ticos (Python)

Para poblar la base se utilizÃ³:

psycopg2 â†’ conexiÃ³n a PostgreSQL

Faker â†’ generaciÃ³n de datos realistas

random y numpy â†’ control vÃ­a seed (RANDOM_SEED = 42)

Funciones auxiliares para:

distribuciones horarias realistas de viajes

validaciÃ³n de consistencia temporal

simulaciÃ³n de rutas, vehÃ­culos, conductores, cargas y estados

creaciÃ³n de logs automÃ¡ticos

Se poblaron todas las tablas manteniendo integridad referencial.

ğŸ” VerificaciÃ³n y ValidaciÃ³n de Datos

Se ejecutaron consultas para validar:

Cantidad de registros por tabla

Primeros registros de cada entidad

Conteo por estado (vehÃ­culos, viajes, entregas)

Viajes por tipo de vehÃ­culo

Entregas por conductor

Consistencia temporal (arrivals > departures)

Fechas de ingesta en logs

ğŸ“Š Avance 2 â€“ AnÃ¡lisis de Queries Operativas

Se ejecutaron 12 queries orientadas a problemas reales de negocio:

ğŸ”¹ Queries bÃ¡sicas

ComposiciÃ³n de la flota

Conductores con licencia prÃ³xima a vencer

Viajes por estado

ğŸ”¹ Queries intermedias

Demanda por ciudad

Conductores activos con mÃ¡s viajes completados

Promedio de entregas por conductor

ğŸ”¹ Queries complejas

Costo de mantenimiento por kilÃ³metro

Entregas por dÃ­a y horario de semana

Para cada una se analizÃ³ el plan de ejecuciÃ³n, se justificÃ³ la necesidad operativa y se crearon Ã­ndices optimizadores comparando tiempos con y sin Ã­ndice.

â„ï¸ Avance 3 â€“ MigraciÃ³n a Snowflake

Se creÃ³ un entorno OLTP equivalente en Snowflake:

âœ” Proceso realizado

ConexiÃ³n desde Python

Carga de mÃºltiples DataFrames con datos exportados de PostgreSQL

TransformaciÃ³n y limpieza segÃºn estructura del warehouse

CreaciÃ³n de vistas

VerificaciÃ³n de cargas completas

Script de automatizaciÃ³n de ingestas diarias

â˜ï¸ Avance 4 â€“ Arquitectura Cloud en AWS

Se diseÃ±Ã³ e implementÃ³ una arquitectura para ingesta y anÃ¡lisis en tiempo real:

ğŸ—ï¸ Arquitectura Serverless AWS
ğŸ”¹ Capa 1 â€“ Entrada

API Gateway recibe eventos desde la app mÃ³vil:

Estado de entregas

GPS del conductor

Inicio/fin de viajes

ğŸ”¹ Capa 2 â€“ Procesamiento

Funciones AWS Lambda:

Verificar entrega (API Gateway â†’ Lambda â†’ DynamoDB)

Calcular ETA cada 5 minutos (EventBridge)

Detectar desvÃ­os de ruta (Kinesis â†’ Lambda â†’ SNS)

ğŸ”¹ Capa 3 â€“ Almacenamiento

DynamoDB: estados, tracking, alertas

S3: datos histÃ³ricos, backups, logs

RDS PostgreSQL: sistema transaccional base

ğŸ”¹ Capa 4 â€“ Notificaciones

SNS para alertas inmediatas

EventBridge para automatizaciones programadas

ğŸ§° Script de AWS Automation (aws_setup.py)

Crea automÃ¡ticamente:

Recurso	Servicio	FunciÃ³n
RDS PostgreSQL	Amazon RDS	Base relacional transaccional
Bucket S3	Amazon S3	Almacenamiento raw/processed/backups
Tablas DynamoDB	AWS DynamoDB	Tracking, alertas, estados
IAM Role para Lambda	AWS IAM	Permisos para acceso entre servicios
Snapshot inicial	RDS	Backups automÃ¡ticos
Script migrate_to_rds.sh	Shell	MigraciÃ³n de BD local a RDS

Incluye funciones como:

crear_rds_postgresql()

crear_s3_bucket()

crear_dynamodb_tables()

crear_iam_role_lambda()

generaciÃ³n de estructura y polÃ­ticas (Lifecycle, Tags, etc.)

ğŸ§  ConclusiÃ³n del Proyecto

El proyecto FleetLogix integra:

âœ” Modelado relacional
âœ” GeneraciÃ³n masiva de datos sintÃ©ticos
âœ” Queries avanzadas para resolver problemas reales
âœ” MigraciÃ³n y ejecuciÃ³n en Snowflake
âœ” Arquitectura cloud escalable y serverless en AWS
âœ” Pipelines automÃ¡ticos y buenas prÃ¡cticas de ingenierÃ­a de datos

Se logrÃ³ transformar un modelo transaccional bÃ¡sico en una soluciÃ³n moderna orientada a anÃ¡lisis en tiempo real y toma de decisiones basada en datos.
